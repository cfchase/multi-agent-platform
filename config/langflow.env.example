# LangFlow Container Environment Variables
# Copy to langflow.env and fill in values.
# These are forwarded to the LangFlow container as global variables
# so flows can reference them without hardcoding secrets.

# LLM API Keys (optional â€” only set the providers you use)
OPENAI_API_KEY=
GEMINI_API_KEY=
ANTHROPIC_API_KEY=

# Ollama base URL (for local LLM inference)
# Default: http://host.containers.internal:11434 (container-to-host networking)
# OLLAMA_BASE_URL=http://host.containers.internal:11434

# Web Search Configuration (Phase 4.1)
# DuckDuckGo requires no API key (preferred)
# Fallback options if DuckDuckGo doesn't work:
# TAVILY_API_KEY=your-tavily-key-here
# GOOGLE_API_KEY=your-google-api-key-here
# GOOGLE_CSE_ID=your-custom-search-engine-id

# ========================================
# Langfuse Tracing (Phase 4.2)
# ========================================
# Automatically traces all LangFlow executions to Langfuse.
# Default values work with local dev Langfuse (make langfuse-start).
# Uncomment and set these to enable tracing.
LANGFUSE_SECRET_KEY=sk-dev-secret-key
LANGFUSE_PUBLIC_KEY=pk-dev-public-key
# LANGFUSE_HOST is computed by dev-langflow.sh using container networking.
# Only override if using a non-local Langfuse instance.
# LANGFUSE_HOST=http://host.docker.internal:3000
